{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b890ed15",
   "metadata": {},
   "source": [
    "\n",
    "# Student Performance Analytics: A Data Science Project\n",
    "\n",
    "This project focuses on predicting student academic performance. We will investigate how student data, including demographic, social, and school-related attributes, along with early academic performance indicators, can be leveraged to identify students at risk of academic failure, understand drivers of course engagement, and facilitate personalized learning interventions.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Student performance is a critical indicator of educational system effectiveness. Traditional assessment methods often lack the holistic view or early warning signs needed to address potential issues proactively. This project utilizes data-driven approaches to provide insights and predictive capabilities for educational improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944c16ed",
   "metadata": {},
   "source": [
    "\n",
    "## Data Sourcing and Description\n",
    "\n",
    "This project utilizes the **Student Performance Data Set** from the UCI Machine Learning Repository [1]. This dataset contains student academic performance data from two Portuguese secondary schools, covering two distinct subjects: Mathematics and Portuguese language.\n",
    "\n",
    "**Dataset Source:** [UCI Machine Learning Repository - Student Performance](https://archive.ics.uci.edu/dataset/320/student+performance)\n",
    "\n",
    "### Dataset Files\n",
    "\n",
    "*   `student-mat.csv`: Contains data for students in a Mathematics course.\n",
    "*   `student-por.csv`: Contains data for students in a Portuguese language course.\n",
    "\n",
    "### Features\n",
    "\n",
    "The dataset includes 33 attributes for each student, categorized as follows:\n",
    "\n",
    "*   **Demographic Information:** `sex`, `age`, `address`, `famsize`, `Pstatus`, `Medu` (mother's education), `Fedu` (father's education).\n",
    "*   **Social and Personal Factors:** `Mjob` (mother's job), `Fjob` (father's job), `reason` (reason to choose school), `guardian`, `traveltime`, `studytime`, `failures`, `schoolsup` (extra educational support), `famsup` (family educational support), `paid` (extra paid classes), `activities` (extra-curricular activities), `nursery` (attended nursery school), `higher` (wants to take higher education), `internet` (Internet access), `romantic` (with a romantic relationship), `famrel` (quality of family relationships), `freetime`, `goout` (going out with friends), `Dalc` (workday alcohol consumption), `Walc` (weekend alcohol consumption), `health` (current health status), `absences`.\n",
    "*   **School-related Information:** `school` (student's school), `course` (subject: Math or Portuguese).\n",
    "*   **Grades:** `G1` (first period grade), `G2` (second period grade), `G3` (final grade).\n",
    "\n",
    "**Note:** The target variable for prediction in this project is `G3`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02382472",
   "metadata": {},
   "source": [
    "\n",
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "We will clean and preprocess the raw datasets, preparing them for exploratory data analysis and machine learning model training. The goal is to combine the two subject-specific datasets, handle categorical variables, and ensure data consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc627d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Loading the Data ---\n",
    "print(\"Loading student-mat.csv...\")\n",
    "mat_df = pd.read_csv('student-mat.csv', delimiter=';')\n",
    "print(\"Loading student-por.csv...\")\n",
    "por_df = pd.read_csv('student-por.csv', delimiter=';')\n",
    "\n",
    "# Displaying the Data before being proccessed\n",
    "print('Displaying the Mathematics Dataset')\n",
    "print(mat_df)\n",
    "print('Displaying the Portuguese Dataset')\n",
    "print(por_df)\n",
    "\n",
    "# --- Add Subject Column and Combine DataFrames ---\n",
    "# We add a new 'subject' column to differentiate between Mathematics and Portuguese students.\n",
    "# The two dataframes will then be concatenated to create a single, comprehensive dataset.\n",
    "print(\"Adding 'subject' column and combining dataframes...\")\n",
    "mat_df['subject'] = 'Math'\n",
    "por_df['subject'] = 'Portuguese'\n",
    "combined_df = pd.concat([mat_df, por_df], ignore_index=True)\n",
    "\n",
    "# --- Data Cleaning: Strip Whitespace from String Columns ---\n",
    "# This step ensures consistency by removing leading/trailing whitespace from all string-type columns.\n",
    "print(\"Cleaning string columns (stripping whitespace)...\")\n",
    "for col in combined_df.select_dtypes(include=['object']).columns:\n",
    "    combined_df[col] = combined_df[col].str.strip()\n",
    "\n",
    "# --- Save Combined Data ---\n",
    "# The combined and cleaned dataset is saved to a new CSV file for future use.\n",
    "print(\"Saving combined_student_performance.csv...\")\n",
    "combined_df.to_csv('combined_student_performance.csv', index=False)\n",
    "print(\"combined_student_performance.csv created.\")\n",
    "print(\"Shape of combined_df:\", combined_df.shape)\n",
    "print(\"First 5 rows of combined_df:\")\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Feature Engineering and Encoding ---\n",
    "# We will handle categorical variables by converting them into a numerical format\n",
    "# suitable for machine learning models. Binary categorical variables are mapped to 0/1,\n",
    "# and multi-category nominal variables are one-hot encoded.\n",
    "\n",
    "print(\"Starting feature engineering and encoding...\")\n",
    "\n",
    "# Identify binary and multi-category nominal columns\n",
    "binary_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'subject']\n",
    "nominal_cols = ['Mjob', 'Fjob', 'reason', 'guardian']\n",
    "\n",
    "# Apply one-hot encoding to nominal columns\n",
    "print(\"Applying one-hot encoding to nominal columns...\")\n",
    "combined_df_encoded = pd.get_dummies(combined_df, columns=nominal_cols, drop_first=True)\n",
    "\n",
    "# Convert binary columns to numerical (0 and 1)\n",
    "print(\"Converting binary columns to numerical (0 and 1)...\")\n",
    "for col in binary_cols:\n",
    "    if col in combined_df_encoded.columns:\n",
    "        unique_values = combined_df_encoded[col].unique()\n",
    "        if len(unique_values) == 2:\n",
    "            mapping = {unique_values[0]: 0, unique_values[1]: 1}\n",
    "            combined_df_encoded[col] = combined_df_encoded[col].map(mapping)\n",
    "        else:\n",
    "            print(f\"Warning: Column {col} is not binary or has more than 2 unique values after encoding. Skipping direct 0/1 mapping.\")\n",
    "\n",
    "# --- Save Preprocessed Data ---\n",
    "# We will save the fully preprocessed dataset to a new CSV file.\n",
    "print(\"Saving preprocessed_student_performance.csv...\")\n",
    "combined_df_encoded.to_csv('preprocessed_student_performance.csv', index=False)\n",
    "print(\"preprocessed_student_performance.csv created.\")\n",
    "print(\"Shape of preprocessed_student_performance.csv:\", combined_df_encoded.shape)\n",
    "print(\"First 5 rows of preprocessed_student_performance.csv:\")\n",
    "print(combined_df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7f1a3",
   "metadata": {},
   "source": [
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "We will perform Exploratory Data Analysis (EDA) to understand the dataset's characteristics, identify patterns, and visualize relationships between variables. This will help us in gaining insights into student performance and potential influencing factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74011895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the preprocessed data\n",
    "print(\"Loading preprocessed_student_performance.csv for EDA...\")\n",
    "combined_df = pd.read_csv(\"preprocessed_student_performance.csv\")\n",
    "\n",
    "# --- Descriptive Statistics ---\n",
    "# Display descriptive statistics for numerical columns and value counts for key categorical columns.\n",
    "print(\"Descriptive statistics for numerical features:\")\n",
    "print(combined_df.describe())\n",
    "\n",
    "print(\"Value counts for key categorical features (after encoding, some might be 0/1):\")\n",
    "print(\"School:\", combined_df['school'].value_counts())\n",
    "print(\"Sex:\", combined_df['sex'].value_counts())\n",
    "print(\"Address:\", combined_df['address'].value_counts())\n",
    "print(\"Subject:\", combined_df['subject'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172cdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Visualization 1: Distribution of Final Grades (G3) ---\n",
    "# This histogram will visualize the distribution of the final grade (G3).\n",
    "# It will helps us to understand the spread and common grade ranges among students.\n",
    "print(\"Generating G3 distribution histogram...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(combined_df['G3'], kde=True, bins=20)\n",
    "plt.title('Distribution of Final Grades (G3)')\n",
    "plt.xlabel('Final Grade (G3)')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.savefig('g3_distribution.png')\n",
    "plt.show()\n",
    "print(\"g3_distribution.png created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6776ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Visualization 2: Correlation Heatmap of Numerical Features ---\n",
    "# This heatmap shows the correlation matrix for all numerical features.\n",
    "# It helps identify linear relationships between variables, especially with the target variable G3.\n",
    "print(\"Generating correlation heatmap...\")\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(combined_df.corr(numeric_only=True), annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.show()\n",
    "print(\"correlation_heatmap.png created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Visualization 3: Box Plots of G3 by Categorical Features ---\n",
    "# These box plots will compare the distribution of final grades (G3) across different categories\n",
    "# of key nominal and binary features. This helps in understanding how these factors\n",
    "# relate to academic performance.\n",
    "print(\"Generating box plots for G3 by categorical features...\")\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.boxplot(x='school', y='G3', data=combined_df)\n",
    "plt.title('G3 by School')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.boxplot(x='sex', y='G3', data=combined_df)\n",
    "plt.title('G3 by Sex')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.boxplot(x='address', y='G3', data=combined_df)\n",
    "plt.title('G3 by Address')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.boxplot(x='famsize', y='G3', data=combined_df)\n",
    "plt.title('G3 by Family Size')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.boxplot(x='Pstatus', y='G3', data=combined_df)\n",
    "plt.title('G3 by Parents Cohabitation Status')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.boxplot(x='subject', y='G3', data=combined_df)\n",
    "plt.title('G3 by Subject')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('categorical_g3_boxplots.png')\n",
    "plt.show()\n",
    "print(\"categorical_g3_boxplots.png created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaddc541",
   "metadata": {},
   "source": [
    "\n",
    "## Methodology / Implementation\n",
    "\n",
    "### 1. Feature and Target Definition\n",
    "\n",
    "*   **Target Variable (y):** The final grade (`G3`) was selected as the target variable for prediction.\n",
    "*   **Feature Variables (X):** All other preprocessed columns were considered as features. Crucially, the `G1` (first period grade) and `G2` (second period grade) were *excluded* from the feature set. This decision is made to address the challenge highlighted by the dataset creators: predicting `G3` without `G1` and `G2` is more difficult but significantly more useful for early intervention strategies.\n",
    "\n",
    "### 2. Data Splitting\n",
    "\n",
    "The preprocessed dataset was will be split into training and testing sets (80% for training, 20% for testing) using `random_state=42` for reproducibility.\n",
    "\n",
    "### 3. Model Selection and Training\n",
    "\n",
    "Three distinct regression models will be selected for their varying approaches to capturing relationships within the data:\n",
    "\n",
    "*   **Linear Regression:** A baseline model for understanding linear relationships.\n",
    "*   **Random Forest Regressor:** An ensemble method robust against overfitting and capable of handling non-linear relationships.\n",
    "*   **Gradient Boosting Regressor:** A powerful ensemble technique known for high predictive accuracy by iteratively correcting errors.\n",
    "\n",
    "### 4. Model Persistence\n",
    "\n",
    "Each trained model will be saved using the `joblib` library for later use and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c231af7",
   "metadata": {},
   "source": [
    "\n",
    "## Model Building and Training\n",
    "\n",
    " We will now be preparing the data for modeling, splitting it into training and testing sets, training the selected regression models, and saving the trained models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import joblib\n",
    "\n",
    "# Load the preprocessed data\n",
    "print(\"Loading preprocessed_student_performance.csv for model building...\")\n",
    "combined_df = pd.read_csv(\"preprocessed_student_performance.csv\")\n",
    "\n",
    "# --- Define Features (X) and Target (y) ---\n",
    "# G1 and G2 will be excluded from features to make the prediction more challenging and useful for early intervention.\n",
    "print(\"Defining features (X) and target (y). G1 and G2 are excluded from features.\")\n",
    "X_all = combined_df.drop([\"G1\", \"G2\", \"G3\"], axis=1)\n",
    "y = combined_df[\"G3\"]\n",
    "\n",
    "# Convert boolean columns to int for model compatibility if any exist\n",
    "# This step ensures that any remaining boolean columns (from one-hot encoding) are numerical.\n",
    "print(\"Converting boolean columns to int for model compatibility...\")\n",
    "for col in X_all.select_dtypes(include=[\"bool\"]).columns:\n",
    "    X_all[col] = X_all[col].astype(int)\n",
    "\n",
    "# --- Split Data into Training and Testing Sets ---\n",
    "# The data is split into 80% for training and 20% for testing to evaluate model performance on unseen data.\n",
    "print(\"Splitting data into training (80%) and testing (20%) sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "# --- Save Test Data ---\n",
    "# The test data (features and target) will be saved to CSV files. These will be used later for model evaluation.\n",
    "print(\"Saving X_test.csv and y_test.csv...\")\n",
    "X_test.to_csv(\"X_test.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)\n",
    "print(\"X_test.csv and y_test.csv created.\")\n",
    "\n",
    "# --- Initialize and Train Models ---\n",
    "# Three regression models will be initialized and trained on the training data.\n",
    "# Each trained model will then be saved using joblib for persistence.\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{name} trained.\")\n",
    "    # Save the trained model to a .pkl file\n",
    "    joblib.dump(model, f\"{name.replace(' ', '_').lower()}.pkl\")\n",
    "    print(f\"Saved {name} model to {name.replace(' ', '_').lower()}.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15cb61",
   "metadata": {},
   "source": [
    "\n",
    "## Statistical Analysis and Evaluation\n",
    "\n",
    "This section focuses on evaluating the performance of the trained machine learning models using standard regression metrics. It also discusses the assumptions made and the limitations of the current approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- Load Test Data ---\n",
    "# The previously saved test data is loaded to evaluate the trained models.\n",
    "print(\"Loading X_test.csv and y_test.csv for evaluation...\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "\n",
    "# Convert boolean columns to int for model compatibility if any exist\n",
    "# This ensures consistency with the format used during model training.\n",
    "print(\"Converting boolean columns in X_test to int...\")\n",
    "for col in X_test.select_dtypes(include=[\"bool\"]).columns:\n",
    "    X_test[col] = X_test[col].astype(int)\n",
    "\n",
    "# --- Load Trained Models ---\n",
    "# The trained models (saved as .pkl files) are loaded for prediction.\n",
    "print(\"Loading trained models...\")\n",
    "models = {\n",
    "    \"Linear Regression\": joblib.load(\"linear_regression.pkl\"),\n",
    "    \"Random Forest Regressor\": joblib.load(\"random_forest_regressor.pkl\"),\n",
    "    \"Gradient Boosting Regressor\": joblib.load(\"gradient_boosting_regressor.pkl\")\n",
    "}\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "# Each model's performance is evaluated using MAE, MSE, RMSE, and R-squared.\n",
    "print(\"Model Evaluation Results:\")\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse**0.5 # Root Mean Squared Error\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"R-squared (R2): {r2:.2f}\")\n",
    "\n",
    "# --- Save Evaluation Results ---\n",
    "# The evaluation results are compiled into a DataFrame and saved to a CSV file.\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Summary of Model Evaluation:\")\n",
    "print(results_df)\n",
    "results_df.to_csv(\"model_evaluation_results.csv\")\n",
    "print(\"Model evaluation results saved to model_evaluation_results.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d3c774",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion and References\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This research project successfully demonstrated the application of data science techniques to predict student academic performance and identify influential factors within secondary education. The Gradient Boosting Regressor emerged as the most effective model, providing a valuable tool for forecasting student final grades even with the intentional exclusion of highly correlated prior grades (G1 and G2), thereby enhancing its utility for early intervention strategies.\n",
    "\n",
    "The findings from the exploratory data analysis and model evaluation underscore the complex interplay of demographic, social, and school-related factors in shaping student outcomes. Key insights revealed the significant impact of parental education, study time, and past academic failures on final grades. The proposed innovative applications—including an interactive dashboard, an early warning system API, and a personalized learning recommendations engine—illustrate the potential for translating these analytical insights into practical, actionable tools.\n",
    "\n",
    "### References\n",
    "\n",
    "1.  Cortez, P., & Silva, A. M. G. (2008). Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., *Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008)* (pp. 5-12). Porto, Portugal: EUROSIS. ISBN 978-9077381-39-7.\n",
    "2.  UCI Machine Learning Repository: Student Performance. (n.d.). Retrieved from [https://archive.ics.uci.edu/dataset/320/student+performance](https://archive.ics.uci.edu/dataset/320/student+performance)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
